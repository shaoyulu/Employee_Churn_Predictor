{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Why this project is important? What problem are you trying to solve?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are trying to help the company to study the employee attrition rate. A HubSpot report found that the employee turnover lost productivity costs U.S. businesses a shocking 1.8 trillion every year. Some studies predict that every time a business replaces a salaried employee, it costs 6 to 9 months' salary on average. For an employee making 60,000 a year, that's 30,000 to 45,000 in recruiting and training expenses. Predicting employee attrition is very important and there are several reasons: \n",
    "\n",
    "**Retention and Cost**: Employee attrition can be costly for a company. It involves expenses reated to hiring and training new employees, as well as the potential loss of productivity during the transition period. \n",
    "\n",
    "**Employee Satisfaction and Engagement**:High attrition rates can be indicative of underlying issues related to employee satisfaction, engagement, and well-being. Investigating attrition helps identify the reasons why employees are leaving, allowing the company to address concerns and improve the work environment.\n",
    "\n",
    "**Talent Acquisition and Employer Branding**: High attrition rates can negatively impact a company's reputation as an employer. Prospective employees may view high turnover as a red flag, affecting the company's ability to attract and retain top talent.\n",
    "\n",
    "**Lost institutional  knowledge**: When highly-skilled or longtime employees leave, your organization loses some institutional knowledge, or the combined skill set and experience of your business.\n",
    "\n",
    "The above are the important reasons for us to help the company study the employee attrition rate. Understanding and predicting employee attrition can assist the company in formulating appropriate strategies to reduce employee turnover, enhance employee satisfaction, and strengthen talent management capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. How do you measure the model performance (metrics)? What is the benchmark?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Business value:**\n",
    "The business value of solving this problem is the ability to identify employee at risk of planing to leave the company and take proactive measures to retain them, leading to improved work environment, retain talented employees, employee satisfaction, reducing the cost for new employee training and then increased revenue.\n",
    "\n",
    "**Benchmark:**\n",
    "We need to establish a benchmark by comparing our model's performance metrics (such as accuracy, precision, recall, or AUC-ROC) against industry standards (typical attrition rates for the company) or previous results achieved by similar studies.\n",
    "The metrics could be the attrition rate: The attrition rate measures the proportion of employees who have left the company and correlated it to the specified conditions, such as employee satisfication, hourly date, promotion... etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. How is your model? Have achieved your goal? How to evaluate the business value of your model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, based on the models, we got ~0.9 precision for RandomForest and Catboost model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Any insights have you gotten from your model? Any actionable suggestions can you provide to your business partner?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the Catboost model to predict the churn and the precision is 0.905. The feature importance can be as suggestion to reduce the churn rate, such as overtime, monthly income.. etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. What is the most challenging part in the project? How did you solve it? How will you futher improve your model if you get more resources and time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most challenging for this project is the exploratory data analysis (EDA) phase, particularly when dealing with a large number of features. Here are the stratgeies:\n",
    "\n",
    "1) Feature selection: we plot different histgram map to check the distribution of each features and remove non relavent features\n",
    "2) Correlation features: we genearte the heatmap to check the correlation for each features and remove the multiconlinearity of features\n",
    "3) Feature engineering: we consider both one-hot encoding and ording encoding for categorical feaetures and we also use Catboost model as comparison for other models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv(\"IBM_HR_Data.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes\n",
    "def convertAttrition(s):\n",
    "    if s==\"Voluntary Resignation\":\n",
    "        return 1\n",
    "    if s==\"Current employee\":\n",
    "        return 0\n",
    "    else:\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "data[\"Attrition\"]=data.Attrition.map(convertAttrition)\n",
    "data=data.dropna(subset=[\"Attrition\"])\n",
    "data.Attrition.value_counts()\n",
    "data_temp=data[[\"Gender\",\"MaritalStatus\",\"Department\",\"EducationField\",\"Employee Source\",\"BusinessTravel\",\"Over18\",\"OverTime\",\"Education\",\"EmployeeCount\",\"EnvironmentSatisfaction\",\"JobInvolvement\",\"JobLevel\",\"JobRole\",\"JobSatisfaction\",\"DistanceFromHome\",\"NumCompaniesWorked\",\"PercentSalaryHike\",\"PerformanceRating\",\"RelationshipSatisfaction\",\"StandardHours\",\"StockOptionLevel\",\"TotalWorkingYears\",\"TrainingTimesLastYear\",\"WorkLifeBalance\",\"YearsAtCompany\",\"YearsInCurrentRole\",\"YearsSinceLastPromotion\",\"YearsWithCurrManager\",\"Attrition\"]]\n",
    "data_temp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "features=[\"Gender\",\"MaritalStatus\",\"Department\",\"EducationField\",\"Employee Source\",\"BusinessTravel\",\"Over18\",\"OverTime\",\"Education\",\"EmployeeCount\",\"EnvironmentSatisfaction\",\"JobInvolvement\",\"JobLevel\",\"JobRole\",\"JobSatisfaction\",\"DistanceFromHome\",\"NumCompaniesWorked\",\"PercentSalaryHike\",\"PerformanceRating\",\"RelationshipSatisfaction\",\"StandardHours\",\"StockOptionLevel\",\"TotalWorkingYears\",\"TrainingTimesLastYear\",\"WorkLifeBalance\",\"YearsAtCompany\",\"YearsInCurrentRole\",\"YearsSinceLastPromotion\",\"YearsWithCurrManager\"]\n",
    "features\n",
    "from IPython.display import display\n",
    "for i in features:\n",
    "    \n",
    "    fig = px.histogram(data_temp, x=\"Attrition\", color=i, barmode=\"stack\", title=i+\" distribution<b>\")\n",
    "    fig.update_layout(width=500, height=350, bargap=0.1)\n",
    "    \n",
    "    fig.update_xaxes(\n",
    "        type=\"category\",\n",
    "        tickvals=[0, 1],\n",
    "        ticktext=[\"0\", \"1\"]\n",
    "    )\n",
    "    \n",
    "    display(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_features_values=[]\n",
    "check_features=[]\n",
    "for i in features:\n",
    "    value_counts_df=pd.DataFrame(data[i].value_counts())\n",
    "    indices=value_counts_df[value_counts_df[i] == 1].index.tolist()\n",
    "    #print(indices)\n",
    "    if len(indices)>0:\n",
    "        for j in range(0,len(indices)):\n",
    "            check_features_values.append(indices[j])\n",
    "            check_features.append(i)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleanup=data\n",
    "for i in range(0,len(check_features_values)):\n",
    "    data_cleanup=data_cleanup[data_cleanup[check_features[i]] != check_features_values[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.set_context(\"paper\")\n",
    "for i in features:\n",
    "    \n",
    "    fig = px.histogram(data_cleanup, x=\"Attrition\", color=i, barmode=\"stack\", title=i+\" distribution<b>\")\n",
    "    fig.update_layout(width=500, height=350, bargap=0.1)\n",
    "    \n",
    "    fig.update_xaxes(\n",
    "        type=\"category\",\n",
    "        tickvals=[0, 1],\n",
    "        ticktext=[\"0\", \"1\"]\n",
    "    )\n",
    "    \n",
    "    display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleanup = data_cleanup.fillna(data_cleanup.mode().iloc[0])\n",
    "data_cleanup[\"Application ID\"].value_counts()\n",
    "data_cleanup = data_cleanup[data_cleanup[\"Application ID\"]!=(\"Test\")]\n",
    "data_cleanup = data_cleanup[data_cleanup[\"EmployeeNumber\"]!=(\"Test\")]\n",
    "data_cleanup = data_cleanup[data_cleanup[\"EmployeeNumber\"]!=(\"TEST\")]\n",
    "data_cleanup = data_cleanup[data_cleanup[\"EmployeeNumber\"]!=(\"TESTING\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleanup['DistanceFromHome'] =data_cleanup['DistanceFromHome'].astype('float64')\n",
    "data_cleanup['EmployeeCount'] =data_cleanup['EmployeeCount'].astype('float64')\n",
    "data_cleanup['EmployeeNumber'] =data_cleanup['EmployeeNumber'].astype('float64')\n",
    "data_cleanup['HourlyRate'] =data_cleanup['HourlyRate'].astype('float64')\n",
    "data_cleanup['JobSatisfaction'] =data_cleanup['JobSatisfaction'].astype('float64')\n",
    "data_cleanup['MonthlyIncome'] =data_cleanup['MonthlyIncome'].astype('float64')\n",
    "data_cleanup['PercentSalaryHike'] =data_cleanup['PercentSalaryHike'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleanup.columns.to_series().groupby(data_cleanup.dtypes).groups\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.set_context(\"paper\")\n",
    "data_cleanup.hist(figsize=(20,20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_cleanup = data_cleanup.drop([\"EmployeeCount\",\"StandardHours\",\"Over18\"], axis=1)\n",
    "feature_numerical=[\"Age\",\"DistanceFromHome\",'Education', 'EmployeeNumber', 'EnvironmentSatisfaction', 'HourlyRate', 'JobInvolvement', 'JobLevel', 'JobSatisfaction', 'MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked', 'PercentSalaryHike', 'PerformanceRating', 'RelationshipSatisfaction', 'StockOptionLevel', 'TotalWorkingYears', 'TrainingTimesLastYear', 'WorkLifeBalance', 'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion', 'YearsWithCurrManager']\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.output{max-height:1000 !important;}</style>\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cat=['BusinessTravel',\n",
    " 'Department',\n",
    " 'EducationField',\n",
    " 'Gender',\n",
    " 'JobRole',\n",
    " 'MaritalStatus',\n",
    " 'OverTime',\n",
    " 'Employee Source',\"DistanceFromHome\"]\n",
    "feature_cat2=[]\n",
    "for column in data_cleanup.columns:\n",
    "    if data_cleanup[column].nunique() < 50:\n",
    "        feature_cat2.append(column)\n",
    "(feature_cat2).remove(\"Attrition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Calculate the number of rows and columns for the subplots\n",
    "num_features = len(feature_cat2)\n",
    "num_rows = 10\n",
    "num_cols = 3\n",
    "\n",
    "# Calculate the total number of subplots\n",
    "num_subplots = num_rows * num_cols\n",
    "\n",
    "# Create the figure and subplots\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(40, 70))\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "# Flatten the axes array for easier indexing\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Iterate over the features and create subplots\n",
    "for i, feature in enumerate(feature_cat2):\n",
    "    if i < num_subplots:\n",
    "        ax = axes[i]\n",
    "        df_EducationField = pd.DataFrame(columns=[\"Field\", \"% of Leavers\"])\n",
    "        j = 0\n",
    "        for field in list(data_cleanup[feature].unique()):\n",
    "            ratio = data_cleanup[(data_cleanup[feature] == field) & (data_cleanup['Attrition'] == 1)].shape[0] / data_cleanup[data_cleanup[feature] == field].shape[0]\n",
    "            df_EducationField.loc[j] = (field, ratio * 100)\n",
    "            j += 1\n",
    "        df_EF = df_EducationField.groupby(by=\"Field\").sum()\n",
    "        x_labels = df_EF.index.tolist()  # Get the categorical values for x-axis labels\n",
    "        ax.bar(x_labels, df_EF['% of Leavers'])\n",
    "        ax.set_xlabel(\"\", fontsize=30)\n",
    "        ax.set_ylabel(\"% of Leavers\", fontsize=30)\n",
    "        ax.set_title(feature, fontsize=30)\n",
    "        ax.tick_params(axis='x', labelsize=30)\n",
    "        ax.tick_params(axis='y', labelsize=30)\n",
    "      #  ax.set_xticks(range(len(x_labels)))\n",
    "      #  ax.set_xticklabels(x_labels, rotation=90, ha='right')\n",
    "\n",
    "        # Mark maximum value with annotation\n",
    "        max_value = df_EF['% of Leavers'].max()\n",
    "        max_index = df_EF['% of Leavers'].idxmax()\n",
    "        ax.annotate(f\"Max: {max_value:.2f}%\", xy=(max_index, max_value), xytext=(0, 5),\n",
    "                    textcoords='offset points', ha='center', fontsize=30, color='red')\n",
    "\n",
    "# Hide the empty subplots if there are any\n",
    "if num_features < num_subplots:\n",
    "    for j in range(num_features, num_subplots):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "# Adjust the layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv(\"cleaned_forOneHot.csv\", low_memory=False)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_order=[\"Age\",\"Gender\",\"MaritalStatus\",\"Education\",\"EducationField\",\"Employee Source\",\"DistanceFromHome\",\"Department\",\"BusinessTravel\",\"JobLevel\",\"JobRole\",\"OverTime\",\"StandardHours\",\"NumCompaniesWorked\",\"EmployeeCount\",\"HourlyRate\",\"DailyRate\",\"MonthlyRate\",\"MonthlyIncome\",\"PercentSalaryHike\",\"StockOptionLevel\",\"TotalWorkingYears\",\"TrainingTimesLastYear\",\"YearsAtCompany\",\"YearsInCurrentRole\",\"YearsSinceLastPromotion\",\"YearsWithCurrManager\",\"JobInvolvement\",\"PerformanceRating\",\"EnvironmentSatisfaction\",\"JobSatisfaction\",\"RelationshipSatisfaction\",\"WorkLifeBalance\",\"Attrition\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =data.reindex(columns=new_order)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data = pd.get_dummies(data, columns=['MaritalStatus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data = pd.get_dummies(encoded_data, columns=['EducationField'])\n",
    "encoded_data = pd.get_dummies(encoded_data, columns=['Employee Source'])\n",
    "encoded_data = pd.get_dummies(encoded_data, columns=['Department'])\n",
    "encoded_data = pd.get_dummies(encoded_data, columns=['JobRole'])\n",
    "encoded_data = pd.get_dummies(encoded_data, columns=['Gender'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data.BusinessTravel.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_order = ['Non-Travel','Travel_Rarely','Travel_Frequently']\n",
    "category_mapping = {category: index for index, category in enumerate(category_order)}\n",
    "encoded_data['BusinessTravel'] = encoded_data['BusinessTravel'].map(category_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_order = ['No','Yes']\n",
    "category_mapping = {category: index for index, category in enumerate(category_order)}\n",
    "encoded_data['OverTime'] = encoded_data['OverTime'].map(category_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertAttrition(s):\n",
    "    if s==\"Voluntary Resignation\":\n",
    "        return 1\n",
    "    if s==\"Current employee\":\n",
    "        return 0\n",
    "    else:\n",
    "        return None\n",
    "encoded_data[\"Attrition\"]=encoded_data.Attrition.map(convertAttrition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_order=['Age', 'Gender_Female', 'Gender_Male','MaritalStatus_Divorced', 'MaritalStatus_Married',\n",
    "       'MaritalStatus_Single','Education','EducationField_Human Resources',\n",
    "       'EducationField_Life Sciences', 'EducationField_Marketing',\n",
    "       'EducationField_Medical', 'EducationField_Other',\n",
    "       'EducationField_Technical Degree', 'EducationField_Test','Employee Source_Adzuna', 'Employee Source_Company Website',\n",
    "       'Employee Source_GlassDoor', 'Employee Source_Indeed',\n",
    "       'Employee Source_Jora', 'Employee Source_LinkedIn',\n",
    "       'Employee Source_Recruit.net', 'Employee Source_Referral',\n",
    "       'Employee Source_Seek', 'Employee Source_Test', 'DistanceFromHome', 'Department_Human Resources', 'Department_Research & Development',\n",
    "       'Department_Sales','BusinessTravel', 'JobLevel','JobRole_Healthcare Representative',\n",
    "       'JobRole_Human Resources', 'JobRole_Laboratory Technician',\n",
    "       'JobRole_Manager', 'JobRole_Manufacturing Director',\n",
    "       'JobRole_Research Director', 'JobRole_Research Scientist',\n",
    "       'JobRole_Sales Executive', 'JobRole_Sales Representative',\n",
    "       'OverTime', 'StandardHours', 'NumCompaniesWorked', 'EmployeeCount',\n",
    "       'HourlyRate', 'DailyRate', 'MonthlyRate', 'MonthlyIncome',\n",
    "       'PercentSalaryHike', 'StockOptionLevel', 'TotalWorkingYears',\n",
    "       'TrainingTimesLastYear', 'YearsAtCompany', 'YearsInCurrentRole',\n",
    "       'YearsSinceLastPromotion', 'YearsWithCurrManager', 'JobInvolvement',\n",
    "       'PerformanceRating', 'EnvironmentSatisfaction', 'JobSatisfaction',\n",
    "       'RelationshipSatisfaction', 'WorkLifeBalance', 'Attrition'\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data =encoded_data.reindex(columns=new_order)\n",
    "\n",
    "encoded_data = encoded_data.drop('StandardHours', axis=1)\n",
    "encoded_data = encoded_data.drop('EmployeeCount', axis=1)\n",
    "encoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_cost_median = encoded_data.corr(method='pearson')\n",
    "filtered_features = []\n",
    "\n",
    "fig, axs = plt.subplots(nrows=11, ncols=4, figsize=(20, 35))\n",
    "\n",
    "for i, feature in enumerate(encoded_data.columns):\n",
    "    row = i // 4  # Changed row and col calculation\n",
    "    col = i % 4\n",
    "\n",
    "    top_10_corr_features = correlation_cost_median[feature].sort_values(ascending=False).head(10)\n",
    "    top_corr_features_filtered = top_10_corr_features[top_10_corr_features > 0.05]\n",
    "\n",
    "    if len(top_corr_features_filtered) >= 2:\n",
    "        filtered_features.append((feature, top_corr_features_filtered[0], top_corr_features_filtered[1]))\n",
    "\n",
    "# Sort the filtered features based on the correlation values of the top two features\n",
    "filtered_features = sorted(filtered_features, key=lambda x: abs(x[1]) + abs(x[2]), reverse=True)\n",
    "\n",
    "for i, (feature, corr1, corr2) in enumerate(filtered_features):\n",
    "    row = i // 4  # Changed row and col calculation\n",
    "    col = i % 4\n",
    "\n",
    "    top_10_corr_features = correlation_cost_median[feature].sort_values(ascending=False).head(10)\n",
    "    top_corr_features_filtered = top_10_corr_features[top_10_corr_features > 0.05]\n",
    "\n",
    "    heatmap = sns.heatmap(top_10_corr_features.values.reshape(-1, 1), annot=True, cmap='coolwarm', vmin=-1, vmax=1, cbar=False, ax=axs[row, col], annot_kws={\"fontsize\": 12})\n",
    "    heatmap.set_title(f'{feature}', fontdict={'fontsize': 12}, pad=12)\n",
    "    heatmap.set_yticklabels(top_10_corr_features.index, rotation=0, fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "encoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=encoded_data[\"Attrition\"]\n",
    "encoded_data_new = encoded_data.drop('Attrition', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(encoded_data_new, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling :  We first check the simplest logisticRegression as a baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "steps = [('rescale', MinMaxScaler()),\n",
    "         ('logr', LogisticRegression(max_iter=1000))]\n",
    "model = Pipeline(steps)\n",
    "model = model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc_roc = roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: {:.3f}\".format(accuracy))\n",
    "print(\"Precision: {:.3f}\".format(precision))\n",
    "print(\"Recall: {:.3f}\".format(recall))\n",
    "print(\"F1-score: {:.3f}\".format(f1))\n",
    "print(\"AUC-ROC: {:.3f}\".format(auc_roc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Confusion Matrix\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, model.predict(X_test))\n",
    "class_names=[0,1] # name  of classes\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "# create heatmap\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the predicted probabilities for the positive class\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Compute the false positive rate (FPR), true positive rate (TPR), and thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "# Calculate the AUC-ROC\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label='ROC curve (AUC = {:.3f})'.format(auc))\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc_roc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Accuracy: {:.3f}\".format(accuracy))\n",
    "print(\"Precision: {:.3f}\".format(precision))\n",
    "print(\"Recall: {:.3f}\".format(recall))\n",
    "print(\"F1-score: {:.3f}\".format(f1))\n",
    "print(\"AUC-ROC: {:.3f}\".format(auc_roc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Confusion Matrix\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, model.predict(X_test))\n",
    "class_names=[0,1] # name  of classes\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "# create heatmap\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rf_classifier = RandomForestClassifier(class_weight = \"balanced\",random_state=7)\n",
    "param_grid = {'n_estimators': [50, 75, 100, 125, 150, 175],\n",
    "              'min_samples_split':[2,4,6,8,10],\n",
    "              'min_samples_leaf': [1, 2, 3, 4],\n",
    "              'max_depth': [5, 10, 15, 20, 25]}\n",
    "\n",
    "grid_obj = GridSearchCV(rf_classifier,\n",
    "                        return_train_score=True,\n",
    "                        param_grid=param_grid,\n",
    "                        scoring='roc_auc',\n",
    "                        cv=10)\n",
    "\n",
    "grid_fit = grid_obj.fit(X_train, y_train)\n",
    "rf_opt = grid_fit.best_estimator_\n",
    "\n",
    "print('='*20)\n",
    "print(\"best params: \" + str(grid_obj.best_estimator_))\n",
    "print(\"best params: \" + str(grid_obj.best_params_))\n",
    "print('best score:', grid_obj.best_score_)\n",
    "print('='*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) xgboostclassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "model = xgb.XGBClassifier()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc_roc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Accuracy: {:.3f}\".format(accuracy))\n",
    "print(\"Precision: {:.3f}\".format(precision))\n",
    "print(\"Recall: {:.3f}\".format(recall))\n",
    "print(\"F1-score: {:.3f}\".format(f1))\n",
    "print(\"AUC-ROC: {:.3f}\".format(auc_roc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Confusion Matrix\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, model.predict(X_test))\n",
    "class_names=[0,1] # name  of classes\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "# create heatmap\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Attrition\"]=data.Attrition.map(convertAttrition)\n",
    "y=data[\"Attrition\"]\n",
    "data_cat = data.drop('Attrition', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features=[1,2,4,5,7,8,10,11]\n",
    "X = data.drop('Attrition', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import catboost as cb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming you have your feature data X and target variable y\n",
    "\n",
    "# Step 1: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Create and train the CatBoost model\n",
    "model = cb.CatBoostClassifier(iterations=1000, learning_rate=0.1, random_seed=42)\n",
    "model.fit(X_train, y_train, cat_features)\n",
    "\n",
    "# Step 3: Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Step 4: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc_roc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Accuracy: {:.3f}\".format(accuracy))\n",
    "print(\"Precision: {:.3f}\".format(precision))\n",
    "print(\"Recall: {:.3f}\".format(recall))\n",
    "print(\"F1-score: {:.3f}\".format(f1))\n",
    "print(\"AUC-ROC: {:.3f}\".format(auc_roc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = model.feature_importances_\n",
    "\n",
    "# Print feature importance scores\n",
    "for feature_name, importance in zip(X.columns, feature_importance):\n",
    "    print(f\"{feature_name}: {importance}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "# Assuming you have the feature importance scores stored in a variable named 'feature_importance'\n",
    "# and the corresponding feature names in a variable named 'feature_names'\n",
    "\n",
    "# Sort the feature importance values and feature names together\n",
    "sorted_indices = feature_importance.argsort()[::-1]\n",
    "sorted_feature_importance = feature_importance[sorted_indices]\n",
    "sorted_feature_names = [X.columns[i] for i in sorted_indices]\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "# Create a colormap\n",
    "colormap = cm.get_cmap('viridis', len(sorted_feature_importance))\n",
    "\n",
    "# Plot the feature importance with color\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(range(len(sorted_feature_importance)), sorted_feature_importance, color=colormap(np.arange(len(sorted_feature_importance))))\n",
    "\n",
    "plt.xticks(range(len(sorted_feature_importance)), sorted_feature_names, rotation='vertical')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Feature Importance')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add a colorbar for reference\n",
    "sm = cm.ScalarMappable(cmap=colormap)\n",
    "sm.set_array([])  # dummy array for the colorbar\n",
    "cbar = plt.colorbar(sm)\n",
    "cbar.set_label('Importance', rotation=90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  # import 'train_test_split'\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Libraries for data modelling\n",
    "from sklearn import svm, tree, linear_model, neighbors\n",
    "from sklearn import naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# selection of algorithms to consider and set performance measure\n",
    "models = []\n",
    "models.append(('Logistic Regression', LogisticRegression(solver='liblinear', random_state=7,\n",
    "                                                         class_weight='balanced')))\n",
    "models.append(('Random Forest', RandomForestClassifier(\n",
    "    n_estimators=100, random_state=7)))\n",
    "models.append(('SVM', SVC(gamma='auto', random_state=7)))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('Decision Tree Classifier',\n",
    "               DecisionTreeClassifier(random_state=7)))\n",
    "models.append(('Gaussian NB', GaussianNB()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Common sklearn Model Helpers\n",
    "from sklearn import feature_selection\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "# sklearn modules for performance metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_curve\n",
    "from sklearn.metrics import auc, roc_auc_score, roc_curve, recall_score, log_loss\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score, make_scorer\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "acc_results = []\n",
    "auc_results = []\n",
    "names = []\n",
    "# set table to table to populate with performance results\n",
    "col = ['Algorithm', 'ROC AUC Mean', 'ROC AUC STD', \n",
    "       'Accuracy Mean', 'Accuracy STD']\n",
    "df_results = pd.DataFrame(columns=col)\n",
    "i = 0\n",
    "# evaluate each model using cross-validation\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(\n",
    "        n_splits=10,   shuffle=False)  # 10-fold cross-validation\n",
    "\n",
    "    cv_acc_results = model_selection.cross_val_score(  # accuracy scoring\n",
    "        model, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "\n",
    "    cv_auc_results = model_selection.cross_val_score(  # roc_auc scoring\n",
    "        model, X_train, y_train, cv=kfold, scoring='roc_auc')\n",
    "\n",
    "    acc_results.append(cv_acc_results)\n",
    "    auc_results.append(cv_auc_results)\n",
    "    names.append(name)\n",
    "    df_results.loc[i] = [name,\n",
    "                         round(cv_auc_results.mean()*100, 2),\n",
    "                         round(cv_auc_results.std()*100, 2),\n",
    "                         round(cv_acc_results.mean()*100, 2),\n",
    "                         round(cv_acc_results.std()*100, 2)\n",
    "                         ]\n",
    "    i += 1\n",
    "df_results.sort_values(by=['ROC AUC Mean'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.sort_values(by=[\"Algorithm\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 7))\n",
    "fig.suptitle('Algorithm Accuracy Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(acc_results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
